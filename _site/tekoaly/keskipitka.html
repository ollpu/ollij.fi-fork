<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Keskipitkä versio | Otsikko</title>
<meta name="generator" content="Jekyll v3.9.3" />
<meta property="og:title" content="Keskipitkä versio" />
<meta name="author" content="Olli Järviniemi" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Kuvaus" />
<meta property="og:description" content="Kuvaus" />
<link rel="canonical" href="http://localhost:4000/tekoaly/keskipitka.html" />
<meta property="og:url" content="http://localhost:4000/tekoaly/keskipitka.html" />
<meta property="og:site_name" content="Otsikko" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Keskipitkä versio" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","author":{"@type":"Person","name":"Olli Järviniemi"},"description":"Kuvaus","headline":"Keskipitkä versio","url":"http://localhost:4000/tekoaly/keskipitka.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Otsikko" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Otsikko</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post">

  <header class="post-header">
    <h1 class="post-title">Keskipitkä versio</h1>
  </header>

  <div class="post-content">
    <h1 id="keskipitkä-versio">Keskipitkä versio</h1>

<p>Kerron tässä, minkä vuoksi pidän kohtalaisen todennäköisenä, että tekoäly aiheuttaa eksistentiaalisen katastrofin.</p>

<p>Tietämättä parempaa tapaa kertoa aiheesta, päädyn luettelemaan erinäisiä uskomuksiani aiheeseen liittyen.</p>

<p>1. <em>Tekoälyjärjestelmät pystyvät olemaan valtavan paljon kyvykkäämpiä kuin ihmiset oleellisesti missä tahansa kognitiivisissa tehtävissä.</em></p>

<p>(Arkisempi muotoilu “tekoälyt voivat olla paljon ihmisiä älykkäämpiä” kärsii sanasta “älykkyys”, joka aiheuttaa eri ihmisissä hyvin erilaisia reaktioita, välillä johtaen ajattelun sivuraiteille.)</p>

<p>Ihmisten kyvyt asettavat <em>alarajan</em>, ei ylärajan, sille, kuinka kyvykkäitä tekoälyt voivat olla. Ihmisaivojen suorittamaa työtä voi toistaa tietokoneella. Tietokoneilla ei ole samankaltaisia rajoituksia koskien suoritetun laskennan määrää, informaation prosessointinopeutta tai skaalautuvuutta kuin ihmisillä.</p>

<p>Niin ikään tekoälyt voivat olla <em>laadullisesti</em> parempia kuin ihmiset, samalla tavalla kuin ihmiset ovat laadullisesti kyvykkäämpiä kuin muut eläimet tai jotkin ihmiset ovat valtavan paljon muita parempia yksittäisissä tehtävissä. Ero ei johdu siitä, että ihmiset tekisivät huomattavasti enemmän ajattelua kuin muut eläimet. Ero syntyy siitä, <em>millaisia</em> ajatuksia tai millaista laskentaa tekee.</p>

<p>Suuri osa tekoälyalasta keskittyy kapeisiin tehtäviin (kuten “miten voittaa ihminen gossa”). Silti tekoäly voi olla <em>yleisesti</em> älykäs – samassa mielessä kuin ihmiset kykenevät miettimään koko ympärillä olevaa maailmaa (tai maailmankaikkeutta), ratkomaan hyvin laajaa joukkoa erilaisia ongelmia ja reflektoimaan omia ajatuksiaan. Ihmisten olemassaolo demonstroi, että tämä on mahdollista. Samanlaisen mekanismin voi toteuttaa tietokoneilla.</p>

<p>2. <em>Ihmisiä valtavan paljon kyvykkäämpi tekoäly kykenee aiheuttamaan ihmiskunnan tuhon (tähän tavoitellessaan)</em></p>

<p>Tämä väite vaikuttaa jakavan ihmisiä: jotkut pitävät sitä itsestäänselvyytenä, jotkut taas ovat vahvasti eri mieltä. Päädyn siksi selittämään näkemyksistäni yleisten vastareaktioiden kautta.</p>

<p>Usein ihmiset haluavat jonkin <em>yksittäisen tarinan</em>, miten tällainen valloitus tapahtuisi. Konkreettiset tarinat eivät kuitenkaan ole isoin syy, minkä takia uskon väitteeseen. Minusta se vaikuttaa aika ilmeiseltä, että hyvin älykkäät tekoälyt voivat tehdä hurjia asioita! Selvästi niiden kanssa tulee olla varovainen!</p>

<p>Intuition lähteitä: Aikuiset ihmiset kykenevät aika paljoon sellaiseen, mihin pienet lapset (tai muut eläimet) eivät kykene. Jos voisin ajatella tuhatkertaisella nopeudella – samaan tapaan kuin tietokone-ohjelman saa ajamaan nopeammin lisäämällä laskentatehoa – eli jos muu maailma näyttäytyisi minulle tuhat kertaa hitaammin, pystyisin aika paljoon sellaiseen, mihin en nyt kykene. Pelatessani shakkia maailmanmestaria vastaan <em>tiedän</em>, että tulen häviämään, vaikken tiedä <em>miten</em>. Ihmiskunta nykyään kykenee aika paljoon sellaiseen, mikä olisi muutama vuosisataa sitten näyttänyt taikuudelta. Pitkälti odotan kehittyneiden tekoälyjen tekevän asioita, joita minä tai muut ihmiset eivät yksinkertaisesti osaa ennakoida etukäteen. Kyvykkäät tekoälyt ajattelevat ajatuksia joita ihmiset eivät.</p>

<p>Tästä näkökulmasta on luontevampaa kysyä syitä sille, miksi kehittyneet tekoälyt <em>eivät</em> kykenisi saamaan tavoitteitaan toteutettua.</p>

<p>Yksi vastaus on, että ihmiset ja ihmisjoukot yrittävät (ja ovat yrittäneet) saada valtaa, ja kuinka mikään taho ei ole onnistunut “maailmanvaltauksessa”. En pidä tätä kovin vahvana vasta-argumenttina. Helppo vastaus: <em>ihmiskunta</em> on onnistunut maailmanvalloituksessa. Toinen vastaus: trendin ei tule olettaa jatkuvan, jos sen takana olevat kausaaliset mekanismit merkittävästi muuttuvat. Samoista syistä, joista “kukaan ihminen ei ole ollut ylivoimainen gossa muihin nähden, joten tekoälykään ei tule olemaan ylivoimainen gossa ihmisiin nähden” on huono päätelmä, tulee miettiä tekoälyn kehityksen vaikutuksia pelkästään trendin ekstrapoloimisen sijasta.</p>

<p>Toinen vastaus on puhua siitä, kuinka tekoäly on lopulta vain tietokoneohjelma, eikä se voi tehdä asioita “oikeassa maailmassa”. Nämä ajatukset vaikuttavat pohjautuvan huonoihin abstraktioihin. Erottelu “digitaalisen maailman” ja “fyysisen maailman” välillä ei ole aito. Tekoälyt tietenkin vaikuttavat maailmaan: vaikka ne esimerkiksi “vain tuottaisivat tekstiä”, niin välillä ihmiset tekevät asioita tekstin lukemisen seurauksena ja tuotettu teksti siten johtaa oikean maailman seurauksiin. Tekoälyjä kehitetään nimenomaan sen takia, että niiden avulla saadaan tehtyä asioita. (Käytettävyyden ja tuottavuuden näkökulmasta voisi myös odottaa, että tekoälyt “laitetaan tekemään” enemmän ja enemmän asioita ilman, että ihmiset toimivat välikätenä. Tämä tietysti on se, mitä tällä hetkellä tapahtuu.)</p>

<p>3. <em>Tavoitteiden asettaminen tekoälyihin on avoin ongelma</em></p>

<p>Emme yksinkertaisesti osaa asettaa tavoitteita tekoälyihin. Yksi tarkempi muotoilu tämän korkean tason väitteen taustalla:</p>

<p><em>Syväoppimismallien kouluttaminen jonkin häviöfunktion (engl. loss function) suhteen ei johda malleihin, jotka sisäisesti “välittävät” tästä tavoitteesta</em></p>

<p>Usein tämä idea selitetään tutkimalla vastaavaa tilannetta evoluution ja ihmisten välillä. Evoluutio optimoi lajeja karkeasti lisääntymiseen ja geenien levittämiseen, tarkemmin <em>kelpoisuuteen</em> (engl. fitness). Tämä ei kuitenkaan ole ihmisten tavoite! Ihmiset välittävät asioista, jotka liittyvät tai <em>ovat liittyneet</em> geenien leviämiseen, ei siitä <em>itsestään</em>. Ihmiset tykkäävät sokerista ja syövät makeita asioita, vaikka ne olisivat “evoluution näkökulmasta” haitallisia. Ylipäätään ihmisten tavoitteeet ovat hyvin monenlaisia, ja iso osa niistä on irrallisia lisääntymisestä.</p>

<p>Tyypillisesti tekoälymalleja koulutettaessa etsitään laajasta joukosta mahdollisia malleja parametreja muuttamalla sellaisia, jotka pärjäävät hyvin jonkin tietyn häviöfunktion suhteen. Ajankohtainen esimerkki on suuret kielimallit, joissa mittarina on (karkeasti) “kuinka hyvin malli ennustaa tekstiä”. Tämä ei kuitenkaan johda malliin, joka sisäisesti “tavoittelee” tekstin ennustamista hyvin – aivan kuten evoluution “etsiessä” biologisia organismeja geenien levittämisen pohjalta kyseiset organismit eivät sisäisesti “tavoittele” geeniensä levittämistä.</p>

<p>Sama pätee myös vahvistusoppimisen (engl. reinforcement learning) kontekstissa, jossa häviöfunktion sijaan puhutaan palkkioista (engl. reward). Hämäävästä nimestään huolimatta palkkio <em>määrittelee prosessin, jolla parametreja muutetaan</em>, eikä itsessään ole asia, jota malli sisäisesti tavoittelee. Hieman epätarkka mutta kenties silti hyödyllinen analogia: nämä palkkiot ovat ikään kuin mielihyvän tai kivun signaalit, vahvistaen tietyntyyppistä toimintaa (“älä tee noin” tai “tee enemmän tuon tyyppisiä juttuja”), mutta ne <em>eivät ole mitä varsinaisesti haluamme</em>.</p>

<p>Yleisesti syväoppimisparadigmassa ei ole tapaa saada <em>sisäisiä ominaisuuksia</em> malleihin, vaan optimointi kohdistuu <em>annettuihin tuloksiin</em>. Tekoälyä voi kouluttaa tavoitteella “ennusta tekstiä hyvin”, jolloin mallin <em>käytös</em> vastaa hyvää tekstin ennustamista. Sen sijaan mallin sisäiset ominaisuudet jäävät tuntemattomiksi.</p>

<p>Vaikka siirryttäisiin syväoppimisen ulkopuolelle, niin ihmiskunta ei tällä hetkellä osaa suunnata tekoälyjärjestelmiä kohti (oikean maailman) tavoitteita. Kielimalleilla on kohtalaisen hyvä käsitys esimerkiksi ihmisten arvoista, mutta <em>ymmärrys</em> ei kuitenkaan tarkoita sitä, että malli <em>välittäisi</em>. Emme osaa rakentaa järjestelmää, joka välittäisi: joka oikeasti yrittää tavoitella näiden ihmisten arvojen toteutumista.</p>

<p>(Nopeat reaktiot kuten “voimmehan rakentaa järjestelmän, joka kysyy kielimallilta parasta toimintatapaa ihmisten arvojen näkökulmasta ja joka sitten tekee niin” missaavat pointin. Yhtenä ongelmana tällainen järjestelmä optimoi <em>kielimallin käsitystä</em> ihmisten arvoista, ei ihmisten arvoja. Taas, emme osaa suunnata tekoälyjä kohti niitä <em>oikeita asioita</em>, ainoastaan johonkin “vähän sinne päin”.)</p>

<p>4. <em>Pelkästään tekoälyjen toiminnan tarkastelu on riittämätöntä turvallisuuden määrittämiseksi</em></p>

<p>Kuvitellaan, että koulutamme mallin ja testaamme sen toimintaa. Testatessa kaikki on kunnossa: malli käyttäytyy juuri kuten haluamme. Taustalla voi olla eri syitä:</p>

<ul>
  <li>Hyvä: Malli pyrkii samoisin asioihin kuin me.</li>
  <li>Huono: Malli pyrkii muihin asioihin, mutta testatessa käyttäytyy kuten haluamme, koska testien läpäiseminen on hyödyllistä näiden muiden tavoitteiden kannalta.</li>
</ul>

<p>Nämä kaksi tapausta johtavat samaan käytökseen, joten niitä ei pysty erottelemaan pelkästään käytöksen perusteella. Erottelu vaatii enemmän tietoa: kuinka todennäköisesti tietyntyyppisiä malleja syntyy syväoppimismalleja koulutettaessa tai mitä mallin sisällä tapahtuu.</p>

<p>5. <em>Ihmiskunnalla on hyvin heikko käsitys siitä, mitä syväoppimismallien sisällä tapahtuu</em></p>

<p>Prosessi syväoppimismallien kouluttamisen taustalla on karkeasti: “Aloitetaan satunnaisesta mallista. Katsotaan, kuinka hyvin se pärjää. Muutetaan sitä (automaattisesti) niin, että se olisi toiminut paremmin. Toistetaan.” Käytännössä on todettu, että tällaisten prosessin tuloksina on malleja, jotka pärjäävät hyvin halutulla mittarilla.</p>

<p>Oleellinen pointti: Ihmisillä, jotka käynnistävät tämän prosessin tietokoneellaan (tai laskentakeskuksellaan), ei ole etukäteen tietoa siitä, millainen lopputulos on. Se tiedetään, että se pärjää hyvin. Sitä ei tiedetä, <em>miten</em> tai <em>miksi</em> se pärjää niin hyvin.</p>

<p>Tiedämme kirjaimellisesti yhtään mitään koskien malleja, mutta niin vähän, että väite “emme tiedä, miten mallit toimivat” kuvaa tilannetta hyvin. Olemme kaukana vastauksista korkean tason kysymyksiin kuten “Mitä mallin sisällä tapahtui, kun se antoi tuon vastauksen? Miten se päätyi tulokseensa? Miksi se teki noin eikä näin?”</p>

<p>6. <em>Ongelman haastavuus kasvaa tekoälyjen kehittyessä</em></p>

<p>Ihmisiä älykkäämpien tekoälyjen tapauksessa ei voi laskea esimerkiksi sen varaan, että ihmiset pystyvät arvioimaan, onko tekoälyn toiminta “hyvää” vai “huonoa”. Kyvykkäät tekoälyt pystyvät johtamaan ihmisiä harhaan, ihmiset eivät kykene hahmottamaan tekoälyn toiminnan seurauksia ja tekoäly keksii asioita, joita ei itse keksi.</p>

<p>Yleisemmin: Kyvykkäät tekoälyt kykenevät tekemään asioita, joihin vähemmän kyvykkäät eivät.</p>

<p>Seurauksena uusia ongelmia ilmaantuu mallien kehittyessä. Kenties jotkin ongelmat ilmaantuvat vasta niiden muodostaessa jo merkittävän riskin uhkaskenaarioille. Näitä haasteita tulee ennakoida etukäteen. Jälkikäteen reagointi vain empiirisesti todettuihin ongelmiin ja iteratiiviset lähestymistavat ongelmien poistamiseksi eivät riitä.</p>

<p>(Käytännössä taas uusien kykyjen ilmaantuminen kielimalleihin on ennalta-arvaamatonta ja taas, ymmärrys mallien sisäisestä toiminnasta on hyvin heikkoa.)</p>

<p>7. <em>Ongelman ratkaisemiseen on vain rajallinen määrä aikaa</em></p>

<p>On useampia organisaatioita, jotka eksplisiittisesti yrittävät rakentaa yleistekoälyn. Ajankohtien ennustaminen on vaikeaa. Siitä huolimatta näyttää hyvinkin mahdolliselta, että nämä organisaatiot onnistuvat tässä lähitulevaisuudessa. Tekinen ongelma tulee ratkaista tätä ennen.</p>

<hr />

<p>Miltä uhkaskenaariot näyttävät?</p>

<p>Ajatukseni ovat ennemminikin muotoa “kehittyneet tekoälyt ovat lähtökohtaisesti vaarallisia ja taustalla oleva tekninen ongelma on haastava” kuin tarkkoja ennustuksia siitä, miltä tulevaisuus tulee näyttämään. Tulevaisuuden ennustaminen on vaikeaa. On useamman tyyppisiä uhkaskenaarioita, joita pidän ihan mahdollisina.</p>

<p>Keskeinen epävarmuuteni koskee “lähtönopeuksia” (engl. takeoff speeds): kuinka jatkuvaa tekoälykehitys on? Puhuessani kehityksen jatkuvuudesta tarkoitan nimenomaan <em>jatkuvuutta</em>, en niinkään <em>nopeutta</em>. (Tietokoneiden laskentateho on kasvanut viime vuosikymmeninä nopeasti (eksponentiaalisesti), mutta kasvu on silti ollut ennustettavaa ilman suuria hyppyjä. Sen sijaan ydinaseiden kehitys johti epäjatkuvuuteen räjähdeaseiden voimakkuudessa.)</p>

<p>Jos kehitys on hyvin epäjatkuvaa, eli jossakin kohtaa uusin koulutettu malli on valtavan paljon edellisiä (ja ihmisiä) parempi, näkisin uhkaskenaarioiden olevan muotoa “kaikki ihmiset yhtäkkiä kuolevat” – tai jotakin muuta, missä ihmiset eivät voi jälkikäteen tehdä uhalle mitään (jos he edes ovat siitä tietoisia).</p>

<p>(Yksi syy, miksi odottaa valtavaa hyppyä kehityksessä: Ihmisten kognitiiviset kyvyt, tai ainakin niiden vaikutukset maailmaan, ovat kehittyneet hyvin nopeasti evolutiivisella aikajänteellä. Satoja ja satoja miljoonia vuosia evoluutiota… kunnes muutaman kymmenen tuhannen vuoden aikana kaikki kääntyy päälaelleen, evoluutio ei olekaan enää dominantti voima, maailma muuttuu vuosien eikä miljoonien vuosien aikaskaalalla. Tämä saa harkitsemaan, että yleisälykkyyden luonne on lopulta melko binäärinen: kun asiat alkavat toimimaan, ne toimivat todella hyvin.)</p>

<p>(Toinen huomio: AlphaGo -sarjan mallit oppivat pelaamaan gota päivien aikaikkunassa paremmin kuin mitä kukaan ihminen lajin vuosituhansia pitkän historian aikana. Kehitys “saa” olla ihmisten mittapuulla hyvin nopeaa.)</p>

<p>(Miten tällainen tekoäly tarkalleen ottaisi kontrollin tai yhtäkkiä tappaisi kaikki? En tietenkään tiedä tarkkaa väylää. Keksin toki joitakin reittejä, joita voi hyödyntää – ja joita itse voisin hyödyntää, jos vaikkapa subjektiivinen aikani kuluisi kymmenpotensseja nopeammin ja pyrkisin tähän tavoitteeseen. Pitkälti tosin odotan, että samaan tapaan kuin monet nykyhetken teknologiat näyttävät taikuudelta tuhannen tai parin sadan vuoden takaisille ihmisille, tällainen hyvin kehittynyt tekoäly keksii asioita, mitä minä en nykyisellään kykene keksimään.)</p>

<p>Jos taas kehitys on jatkuvampaa, niin… no, jos tekoälyjä silti vain kehitetään eteenpäin, samat riskit tulevat vastaan, kun ennen pitkää tekoälyistä tulee paljon ihmisiä kyvykkäämpiä. Verrattain pienet erot eri tekoälyjen välillä ei poista riskiä, etenkään jos näitä tekoälyjä ei käytä ongelman ratkaisemiseksi.</p>

<p>Jatkuvamman kehityksen tapauksessa näen tosin myös mahdollisena, että riskit toteutuvat eri tavalla.</p>

<p>Yksi laaja kategoria uhkakuvia: Tekoälyjä kehitetään, ihmiset ottavat tekoälyjä laajemmin käyttöön, näillä tekoälyillä automatisoidaan enemmän ja enemmän asioita, yhä laajempi osuus tehtävistä on yhä enemmän autonomisten tekoälyjen suorittamia. Ihmisten ymmärrys ja kontrolli hiljalleen vähenee. Tekoälyt tekevät asioita, jotka näyttävät hyviltä, mutta jotka ovat lopulta vain “vähän sinne päin”: lukemat mittareilla näyttävät hyviltä, mittari ei vastaa tarkalleen mitä haluamme, todellisuudessa asiat eivät ole hyvin. On erimielisyyttä siitä, kuinka merkittäviä nämä ongelmat ovat. Riippuvuus tekoälyistä, taloudelliset paineet ja teknisten ongelmien haastavuus tekee vaikeaksi tehdä asialle mitään.</p>

<p>Toisaalta <em>instrumentaalinen suppeneminen</em> (engl. instrumental convergence) – idea “monet välitavoitteet (kuten resurssien hankinta) ovat hyödyllisiä riippumatta lopputavoitteesta” – soveltuu edelleen. Tekoälyjärjestelmät, tai ainakin osa niistä, pyrkivät saamaan resursseja ja vaikutusta. Tulevaisuuden suunta määräytyy enenevissä määrin näiden tekoälyjen, ei ihmisten, toiminnan perusteella.</p>

<p>(Miten tarkalleen eksistentiaalinen katastrofi toteutuisi? Tämä kategoria on hyvin laaja ja disjunktiivinen – voi tapahtua näin tai noin tai näin – ja mikään spesifi tarina ei vaikuta minusta erityisen todennäköiseltä. Silti “tekoälyt jatkavat kehitystään, ihmisten ymmärrys ja kontrolli heikkenee” vaikuttaa selvästi tilanteelta, jossa on paljon riskejä ja johon ei haluta päätyä.)</p>

<p>Huomautan, että eri ihmiset pitävät eri uhkakuvia todennäköisinä ja epätodennäköisinä. (Ei sillä, että tämä on välttämättä hyvä asia: päinvastoin erimielisyys ja tietämättömyys tulevasta vaikuttaa huonolta.) Jotkut tietysti eivät pidä uhkia ylipäätään todennäköisinä.</p>

<p>Erimielisyydet eivät välttämättä ratkea lähitulevaisuudessa. Uhkakuvat eivät vaadi, että tulee “varoituslaukauksia” tai pienempiä onnettomuuksia ennen suuria katastrofeja. Monissa niistä asiat <em>näyttävät</em> hyviltä – vaikkeivat ne ole tai koska ongelma ei ole nykyinen malli vaan seuraava tai sitä seuraava – ja siten ei ole yksittäistä hetkeä, joka herättää ihmiset riskeihin.</p>

<p>Itse pidän melko todennäköisenä, että eksistentiaalinen katastrofi – kaikkien ihmisten kuolema tai muuten ihmiskunnan kehityksen katkeaminen – toteutuu tekoälyn seurauksena. En anna tarkkoja lukemia, jotta en anna väärää kuvaa uskomusteni tarkkuudesta, mutta laitan näille lopputuloksille yli 50 prosenttia. (Tässä numeerinen todennäköisyys kuvastaa yksinkertaisesti minun uskomusteni vahvuutta, kuten olen <a href="https://ollij.fi/epi/probabilistinen_ajattelu">toisaalla</a> kirjoittanut.)</p>

<p>Taas, näkemykseni eivät perustu tarkkoihin ennustuksiin koskien lähitulevaisuuden tapahtumia. Matkalla voi tapahtua yllättäviä asioita. Näen kuitenkin tekoälyuhan <em>konvergenttina</em>, lopputulokselta jota kohti sivilisaatiomme on lähtökohtaisesti ajautumassa, enkä epätodennäköisenä sivuhaarana. (Edelleen, lukuisat organisaatiot yrittävät rakentaa yleistekoälyn, laskentakapasiteetin kasvaessa ajan myötä tämän saavuttaminen muuttuu helpommaksi ja tulevaisuudessa parhaat tekoälyt eivät tule olemaan huonompia kuin parhaat vuonna 2023.) Uhan välttäminen vaatii muutosta ihmiskunnan oletuksena olevaan kulkusuuntaan.</p>

  </div>

</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Otsikko</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">{&quot;name&quot;=&gt;&quot;Olli Järviniemi&quot;}</li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>Kuvaus
</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>

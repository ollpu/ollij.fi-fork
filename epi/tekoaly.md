# Tekoälyuhasta

Tekoälyuhan selittäminen on vaikeaa. Päädyn siksi vain linkkaamaan materiaaleja, joissa asia on selitetty hyvin.

[AI Alignment, Explained in 5 Points](https://medium.com/@daniel_eth/ai-alignment-explained-in-5-points-95e7207300e3) (Daniel Eth) on ehkä paras teksti, joka ei vaadi esitietoja.

Tekninen katsaus syväoppimisen näkökulmasta: [The alignment problem from a deep learning perspective](https://arxiv.org/abs/2209.00626) (Richard Ngo, Lawrence Chan, Sören Mindermann).

Eliezer Yudkowskyn [AGI Ruin: A List of Lethalities](https://www.alignmentforum.org/posts/uMQ3cqWDPHhjtiesc/agi-ruin-a-list-of-lethalities) ja Paul Christianon [Where I agree and disagree with Eliezer](https://www.alignmentforum.org/posts/CoZhXrhpQxpy9xw9y/where-i-agree-and-disagree-with-eliezer) ovat varsin hyviä.

*Periaatteessa* näissä dokumenteissa on keskeisimmät asiat tekoälyuhasta teknisenä ongelmana. *Käytännössä* näiden asioiden selittäminen on vaikeaa. Jos kuvittelen aihetta ennestään tuntemattoman lukemassa näitä tekstejä, en usko hänen saavan kaikkia oleellisia pointteja irti. Lisäksi lukijoiden taustat vaihtelevat ja ihmisillä on eri ajatuksia ja päällimmäisiä kysymyksiä, joihin he haluavat vastauksia. (Sitten on myös yleiset epiin liittyvät asiat, joista puhuminen on parempi tehdä [erikseen](/epi/).)

Näiden syiden vuoksi linkkaan lisäksi muita paikkoja, joiden kautta pääsee pidemmälle (mutta joita kaikkia en ole itse perannut läpi):

- [AI Safety FAQ](https://aisafety.info/) (usein kysytyt kysymykset)
- [Robert Miles](https://www.youtube.com/@RobertMilesAI) (videoita)
- [AI Safety Fundamentals](https://course.aisafetyfundamentals.com/alignment) (kurssi)

Ja, no, osaat varmaan itsekin käyttää nettiä ja etsiä itsellesi sopivia materiaaleja.

Huomautan, että ihmiset ovat eri mieltä monista aiheeseen liittyvistä kysymyksistä. Vaikeat ongelmat ovat sellaisia.
